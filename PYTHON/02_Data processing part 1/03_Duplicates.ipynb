{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "modern-metadata",
   "metadata": {},
   "source": [
    "# Duplicates\n",
    "\n",
    "Using the **product_prices_renamed.csv** files:\n",
    "\n",
    "1. check how many rows are duplicated,\n",
    "1. using `duplicated` check which rows were doubled.\n",
    "1. using `drop_duplicates`, remove all duplicates from the output dataset (we assume that a row with a duplicate is an error and needs to be removed) - write the result to a new DataFrame.\n",
    "\n",
    "### Hints:\n",
    "\n",
    "#### Subsection 2:\n",
    "To determine, the number of duplicate rows use the source data and the results from subsection 1.\n",
    "\n",
    "#### Subsection 3:\n",
    "\n",
    "1. first use `duplicated`, to find duplicated rows,\n",
    "1. use `loc` to separate them from the output set,\n",
    "1. use `drop_duplicates` to get only those rows that are duplicated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "brief-cuisine",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicated rows: 21420\n",
      "\n",
      "Duplicated rows:\n",
      "                 province product_types currency  product_group_id  \\\n",
      "1                    ŁÓDŹ           NaN      PLN                 4   \n",
      "9               PODLASKIE           NaN      PLN                 4   \n",
      "10         WARMIA-MASURIA           NaN      PLN                 4   \n",
      "16                 POLAND           NaN      PLN                 4   \n",
      "19      KUYAVIA-POMERANIA           NaN      PLN                 4   \n",
      "...                   ...           ...      ...               ...   \n",
      "149925     GREATER POLAND           NaN      PLN                 4   \n",
      "149926             POLAND           NaN      PLN                 4   \n",
      "149930     WARMIA-MASURIA           NaN      PLN                 4   \n",
      "149937      LESSER POLAND           NaN      PLN                 4   \n",
      "149939            MASOVIA           NaN      PLN                 4   \n",
      "\n",
      "                                    product_line  value     date  \n",
      "1                                bread - per 1kg    NaN   2018-2  \n",
      "9        plain mixed bread (wheat-rye) - per 1kg   3.86   2017-7  \n",
      "10          Poznan wheat flour, bagged - per 1kg   0.95   2009-5  \n",
      "16                               bread - per 1kg    NaN   2017-9  \n",
      "19          Poznan wheat flour, bagged - per 1kg   1.17  2008-11  \n",
      "...                                          ...    ...      ...  \n",
      "149925  buckwheat groats roasted whole - per 1kg   0.00  2008-12  \n",
      "149926  buckwheat groats roasted whole - per 1kg   5.10   2016-5  \n",
      "149930      Poznan wheat flour, bagged - per 1kg   0.99  2010-10  \n",
      "149937   plain mixed bread (wheat-rye) - per 1kg   3.05   2008-6  \n",
      "149939          Masurian barley groats - per 1kg   0.16  2005-10  \n",
      "\n",
      "[42840 rows x 7 columns]\n",
      "\n",
      "DataFrame without duplicates:\n",
      "                 province                       product_types currency  \\\n",
      "0            SUBCARPATHIA                                 NaN      PLN   \n",
      "1                    ŁÓDŹ                                 NaN      PLN   \n",
      "2       KUYAVIA-POMERANIA                                 NaN      PLN   \n",
      "3           LOWER SILESIA                                 NaN      PLN   \n",
      "4          WARMIA-MASURIA                                 NaN      PLN   \n",
      "...                   ...                                 ...      ...   \n",
      "149933            SILESIA                                 NaN      PLN   \n",
      "149934            SILESIA                                 NaN      PLN   \n",
      "149935  KUYAVIA-POMERANIA                                 NaN      PLN   \n",
      "149936               ŁÓDŹ  beet sugar white, bagged - per 1kg      PLN   \n",
      "149938     WARMIA-MASURIA                                 NaN      PLN   \n",
      "\n",
      "        product_group_id                       product_line  value     date  \n",
      "0                      2          pork ham cooked - per 1kg  21.37   2013-3  \n",
      "1                      4                    bread - per 1kg    NaN   2018-2  \n",
      "2                      2    barley groats sausage - per 1kg   3.55  2019-12  \n",
      "3                      2         dressed chickens - per 1kg   6.14   2019-2  \n",
      "4                      2      Italian head cheese - per 1kg   5.63   2002-3  \n",
      "...                  ...                                ...    ...      ...  \n",
      "149933                 2   smoked bacon with ribs - per 1kg  15.95   2015-9  \n",
      "149934                 2    barley groats sausage - per 1kg   4.50   2004-8  \n",
      "149935                 2   pork  meat (raw bacon) - per 1kg  12.15  2016-11  \n",
      "149936                 3                                NaN   0.00   2012-5  \n",
      "149938                 2  boneless beef (sirloin) - per 1kg  11.87  2000-11  \n",
      "\n",
      "[128520 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\n",
    "    '/Users/jeladobos/Documents/Learning/Data Analyst/5th session/Prework/01_Data/product_prices_renamed.csv',\n",
    "    sep=';',  # column separator\n",
    "    decimal='.'  # sign separating the whole and fractional parts of a number\n",
    ")\n",
    "\n",
    "# No of duplicates\n",
    "num_duplicates = data.duplicated().sum()\n",
    "print(f\"Number of duplicated rows: {num_duplicates}\")\n",
    "\n",
    "# Where duplicates are\n",
    "duplicated_rows = data[data.duplicated(keep=False)]  # keep=False to mark all duplicates\n",
    "print(\"\\nDuplicated rows:\")\n",
    "print(duplicated_rows)\n",
    "\n",
    "# delete duplicates\n",
    "data_no_duplicates = data.drop_duplicates()\n",
    "print(\"\\nDataFrame without duplicates:\")\n",
    "print(data_no_duplicates)\n",
    "\n",
    "data_no_duplicates.to_csv('/Users/jeladobos/Documents/Learning/Data Analyst/5th session/1st Day/01_Data/no_duplicates.csv', sep=';', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475242eb-ff5e-44e3-bdcb-af5ed89eebd1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
